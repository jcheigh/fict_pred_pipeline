{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a supplement to 3-6 inference, and it mostly just ensures torch is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.distributions import Beta\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torch.nn.functional import log_softmax\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fae7b577350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.3000, 0.7000],\n",
       "        [0.7000, 0.3000, 0.7000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if .log_prob() broadcasts across a tensor\n",
    "\"\"\"\n",
    "test = torch.tensor(\n",
    "    [\n",
    "    [1., 0., 1.],\n",
    "    [1., 0., 1.]\n",
    "    ]\n",
    ")\n",
    "test_dist = Bernoulli(torch.tensor([0.7]))\n",
    "torch.exp(test_dist.log_prob(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given an NxM matrix and an Bx1 vector, create a tensor size\n",
    "NxMxB which is the vector multiplied by each of the matrix values \n",
    "\"\"\"\n",
    "test_u = torch.tensor(\n",
    "    [\n",
    "    [1., 2., 2.4],\n",
    "    [1., 3., 1.1]\n",
    "    ]\n",
    ")\n",
    "test_W = torch.tensor([1.,1.,2.])\n",
    "\n",
    "test_res = torch.matmul(test_u.unsqueeze(2), test_W.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "assert torch.all(test_res[0, 1] == torch.tensor([2., 2., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9999! = 5.999247074127197\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Numerically stable factorial\n",
    "Uses gamma function\n",
    "\"\"\"\n",
    "factorial = lambda x : torch.exp(torch.lgamma(x+1))\n",
    "\n",
    "assert factorial(torch.tensor(1.)) == torch.tensor(1.)\n",
    "assert factorial(torch.tensor(2.)) == torch.tensor(2.)\n",
    "assert factorial(torch.tensor(3.)) == torch.tensor(6.)\n",
    "print(f\"2.9999! = {factorial(torch.tensor(2.9999))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('fictitious')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3121cab126e9bc214d9c30934815672d7d73cf142023432050561f8ae595f616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
