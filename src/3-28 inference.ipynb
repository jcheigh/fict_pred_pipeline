{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few slight changes from 3-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from scipy import stats\n",
    "from scipy.special import digamma\n",
    "\n",
    "import torch\n",
    "from torch.distributions import Beta, kl_divergence\n",
    "from torch.nn.functional import log_softmax\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6a5ffd7550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these params control the generation scheme (2/10 generation)\n",
    "rho        = 0.8    # polarization\n",
    "pop_size   = 50000  # num individuals\n",
    "epsilon    = 0.05   # expected prop of speech consisting of neutral words\n",
    "pi         = 0.5    # pi == 0.5 => beta mixture symmetrical (choose beta1 with prob pi = 0.5)\n",
    "speech_len = 50     # words per speech\n",
    "lex_size   = 3      # lexicon size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Data Generation...\n",
      "====================\n",
      "Lex Size: 3, Rho: 0.8, N: 50000\n",
      "epsilon: 0.05, pi: 0.5, S: 50\n",
      "\n",
      "True Alpha: 12.673684210526261\n",
      "True Beta: 3.1684210526315644\n",
      "\n",
      "mixture samples: [0 1 0]\n",
      "u samples: [-0.71319006  0.57688516 -0.46523368]\n",
      "y samples: [0 1 0]\n",
      "\n",
      "P(L) = 0.2712550923688634, P(R): 0.04541157429780326, P(N): 0.016666666666666666\n",
      "P(L) = 0.06699318292320035, P(R): 0.24967348374346632, P(N): 0.016666666666666666\n",
      "P(L) = 0.23199533330535926, P(R): 0.08467133336130739, P(N): 0.016666666666666666\n",
      "X samples (counts):\n",
      " [[16 13 14  2  1  2  0  0  2]\n",
      " [ 2  3  3 12 13 15  1  0  1]\n",
      " [15 15  8  3  4  5  0  0  0]]\n",
      "\n",
      "X samples (sequences):\n",
      " [[0 2 2 2 2 0 0 2 0 1 0 4 0 1 1 3 2 1 2 0 0 5 0 1 0 0 1 2 1 1 0 8 2 2 0 1\n",
      "  1 3 1 1 2 0 8 2 1 2 2 5 0 0]\n",
      " [3 4 5 4 5 5 3 3 1 6 5 0 3 8 4 4 3 5 0 3 5 5 3 4 5 4 1 3 5 5 5 3 2 2 2 5\n",
      "  4 5 4 3 4 1 4 3 5 4 3 4 5 4]\n",
      " [1 5 1 0 1 1 1 2 1 0 5 4 4 0 0 1 0 0 3 0 1 0 0 0 5 1 0 5 3 5 0 2 1 1 2 1\n",
      "  0 2 3 0 1 4 2 0 2 2 1 1 4 2]]\n",
      "\n",
      "====================\n",
      "Generation Time: 1.808 seconds for 50000 samples.\n"
     ]
    }
   ],
   "source": [
    "def generate(rho=rho, N=pop_size, epsilon=epsilon, pi=pi, speech_len=speech_len, lex_size=lex_size, verbose='low'):\n",
    "    \"\"\"\n",
    "    Uses 2/10 generation scheme to generate N samples.\n",
    "\n",
    "    Returns:\n",
    "        (X, y), (a, b, rho, epsilon, u, lex_size)\n",
    "        X.size() == [N, S] is a vector of sequences \n",
    "        y.size() == [N] is a vector of political parties\n",
    "        u.shape  == (N,) is a vector of individual stances\n",
    "        rho is true polarization\n",
    "        epsilon is expected prop of neutral words\n",
    "        a, b are true alpha/beta for beta mixture model\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    if verbose in ['mid', 'high']:\n",
    "        print(f'Beginning Data Generation...')\n",
    "        print(f'=' * 20)\n",
    "        \n",
    "    ### get beta mixture model params \n",
    "    sigma = 0.175 * (rho ** 2) - 0.3625 * rho + 0.1875\n",
    "    a     = rho * ((rho * (1 - rho)) / sigma - 1)\n",
    "    b     = (1 - rho) * ((rho * (1 - rho)) / sigma - 1)\n",
    "\n",
    "    if verbose in ['mid', 'high']:\n",
    "        print(f'Lex Size: {lex_size}, Rho: {rho}, N: {pop_size}')\n",
    "        print(f'epsilon: {epsilon}, pi: {pi}, S: {speech_len}\\n')\n",
    "        print(f\"True Alpha: {a}\")\n",
    "        print(f\"True Beta: {b}\\n\")\n",
    "\n",
    "    mean = a / (a + b)\n",
    "    var  = a * b / ((a + b)**2 * (a + b + 1))\n",
    "\n",
    "    if abs(mean - rho) > 10e-15:\n",
    "        print(f'Mean: {mean}')\n",
    "        print(f\"Rho: {rho}\")\n",
    "        raise AssertionError(f\"Mean of BMM params should be rho\")\n",
    "\n",
    "    if abs(var - sigma) > 10e-15:\n",
    "        print(f'Var: {var}')\n",
    "        print(f'Sigma: {sigma}')\n",
    "        raise AssertionError(f\"Var of BMM params should be sigma\")\n",
    "\n",
    "    ### u ~ pi Beta(a, b) + (1 - pi) Beta(b, a)\n",
    "    weights = [pi, 1-pi]\n",
    "    mixture_samples = np.random.choice([0, 1], size=N, p=weights)\n",
    "\n",
    "    u = 2 * np.where(mixture_samples == 1, stats.beta.rvs(a, b, size=N), stats.beta.rvs(b, a, size=N)) - 1\n",
    "\n",
    "    if u.shape != (N,):\n",
    "        raise AssertionError(f\"u.shape should be (N,)\")\n",
    "\n",
    "    if verbose == 'high':\n",
    "        print(f'mixture samples: {mixture_samples[:3]}')\n",
    "        print(f'u samples: {u[:3]}')\n",
    "\n",
    "    ### y = 1(u >= 0)\n",
    "    y = (u >= 0).astype(int)\n",
    "\n",
    "    if verbose == 'high':\n",
    "        print(f'y samples: {y[:3]}\\n')\n",
    "\n",
    "    ### phi is a prob matrix that is a function of u, epsilon\n",
    "    left_prob    = (1 - (u+1)/2) * (1 - epsilon) / lex_size\n",
    "    right_prob   = (u+1)/2 * (1 - epsilon) / lex_size\n",
    "    neutral_prob = np.repeat(epsilon, N) / lex_size\n",
    "    phi          = np.array([left_prob] * lex_size + [right_prob] * lex_size + [neutral_prob] * lex_size).T\n",
    "    \n",
    "    if verbose == 'high':\n",
    "        for i in range(3):\n",
    "            print(f'P(L) = {phi[i,0]}, P(R): {phi[i, lex_size]}, P(N): {phi[i,-1]}')\n",
    "\n",
    "    if phi.shape != (N, 3 * lex_size):\n",
    "        raise AssertionError(f'phi.shape should be (N, V) == (N, 3L)')\n",
    "\n",
    "    if abs(sum(phi[0]) - 1) > 10e-5:\n",
    "        raise AssertionError(f'rows of phi should sum to 1')\n",
    "    \n",
    "    X = np.array([stats.multinomial.rvs(n=speech_len, p=phi[i, :]) for i in range(N)])\n",
    "\n",
    "    if verbose == 'high':\n",
    "        print(f'X samples (counts):\\n {X[:3]}\\n')\n",
    "    \n",
    "    if X.shape != (N, 3 * lex_size):\n",
    "        raise AssertionError(f'X.shape should be (N, V) == (N, 3L)')\n",
    "\n",
    "    if X[:5].sum() != speech_len * 5:\n",
    "        raise AssertionError(f'rows of phi should sum to 1')\n",
    "\n",
    "    expanded_rows = []\n",
    "    for row in X:\n",
    "        expanded_row = np.repeat(np.arange(len(row)), row)\n",
    "        np.random.shuffle(expanded_row)\n",
    "        expanded_rows.append(expanded_row)\n",
    "\n",
    "    X = np.array(expanded_rows, dtype=np.int64)\n",
    "\n",
    "    if X.shape != (N, speech_len):\n",
    "        raise AssertionError(f'X.shape should be (N, S)')\n",
    "    \n",
    "    if verbose == 'high':\n",
    "        print(f'X samples (sequences):\\n {X[:3]}\\n')\n",
    "\n",
    "    X = torch.from_numpy(X).to(torch.float32)\n",
    "    y = torch.from_numpy(y).to(torch.float32)\n",
    "\n",
    "    known   = (X, y)\n",
    "    unknown = (a, b, rho, epsilon, u, lex_size)\n",
    "\n",
    "    if verbose in ['mid', 'high']:\n",
    "        print('=' * 20)\n",
    "        print(f'Generation Time: {round(time.time() - start, 3)} seconds for {N} samples.')\n",
    "\n",
    "    return known, unknown\n",
    "\n",
    "known, unknown = generate(verbose='high')\n",
    "X, y = known\n",
    "a, b, rho, epsilon, u, lex_size = unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size  = 200 ### discretize integral into grid_size linearly spaced pts\n",
    "batch_size = 100 ### num samples processed simultaneously\n",
    "num_epochs = 200 ### number epochs\n",
    "lr         = 0.1 ### learning rate\n",
    "\n",
    "def compute_nll(x_batch, y_batch, log_alpha, log_beta, W):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        (x_batch, y_batch) a batch of B (x,y) samples \n",
    "        (log_alpha, log_beta, W) trainable parameters\n",
    "\n",
    "    Returns:\n",
    "        A scaler quantity s.t. calling .backward() will compute\n",
    "        grad_{theta} (L(theta))\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "def train(X, y, log_alpha=None, log_beta=None, W=None, num_epochs=num_epochs, batch_size=batch_size, grid_size=grid_size, lr=lr, verbose=True, threshold=0.00001, patience=5, speech_len=speech_len, lex_size=lex_size):\n",
    "    if verbose:\n",
    "        print(f'Beginning Inference...')\n",
    "        print(f'=' * 20)\n",
    "        print(f'Hyperparameters:')\n",
    "        print(f'Dataset Length: {len(X)}')\n",
    "        print(f'Number Epochs: {num_epochs}')\n",
    "        print(f'Batch Size: {batch_size}')\n",
    "        print(f'Grid Size: {grid_size}')\n",
    "        print(f\"Learning Rate: {lr}\")\n",
    "        print(f\"Improvement Threshold: {threshold}\")\n",
    "        print(f\"Patience: {patience}\")\n",
    "        print(f'Speech Len: {speech_len}')\n",
    "        print('=' * 20)\n",
    "\n",
    "    ### not strictly necessary \n",
    "    assert len(X) % batch_size == 0\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    dataset    = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    X_batch, y_batch = list(dataloader)[0]\n",
    "\n",
    "    if list(X_batch.size()) != [batch_size, speech_len]:\n",
    "        raise AssertionError(f\"X_ex.size() should be [batch_size, S], got {X_batch.size()}\")\n",
    "\n",
    "    if list(y_batch.size()) != [batch_size]:\n",
    "        raise AssertionError(f\"y_ex.size() should be [batch_size], got {y_batch.size()}\")\n",
    "\n",
    "    if log_alpha is None:\n",
    "        log_alpha = torch.normal(0, math.sqrt(3), size=(1,), requires_grad=True)\n",
    "\n",
    "    if log_beta is None:\n",
    "        log_beta  = torch.normal(0, math.sqrt(3), size=(1,), requires_grad=True)\n",
    "\n",
    "    if W is None:\n",
    "        W = torch.normal(0, 1, size=(3 * lex_size,), requires_grad=True)\n",
    "\n",
    "    print(f'Initial Parameters:')\n",
    "    print(f'Alpha: {torch.exp(log_alpha).item()}')\n",
    "    print(f\"Beta: {torch.exp(log_beta).item()}\")\n",
    "    print(f\"W: {W.data.tolist()}\")\n",
    "\n",
    "    optimizer = SGD([log_alpha, log_beta, W], lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    # Early stopping logic\n",
    "    best_nll = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs}')\n",
    "        ### only step after each epoch\n",
    "        optimizer.zero_grad() \n",
    "        nll = torch.tensor(0.)\n",
    "        \n",
    "        for x_batch, y_batch in dataloader:\n",
    "            nll += compute_nll(x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size)\n",
    "        \n",
    "        nll = nll / len(dataloader.dataset)\n",
    "        nll.backward()\n",
    "        print('=' * 20)\n",
    "        print(f'Log Alpha Grad: {log_alpha.grad}')\n",
    "        print(f'Log Beta Grad: {log_beta.grad}')\n",
    "        print(f'W Grad: {W.grad}')\n",
    "        print('=' * 20)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        current_nll = nll.item()\n",
    "        if current_nll < best_nll - threshold:\n",
    "            best_nll = current_nll\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1}, NLL: {round(nll.item(), 3)}, Alpha: {round(np.exp(log_alpha.item()),3)}, Beta: {round(np.exp(log_beta.item()),3)}, W: {W.tolist()}')\n",
    "            print('=' * 20)\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    final_alpha = np.exp(log_alpha.item())\n",
    "    final_beta  = np.exp(log_beta.item())\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Training Took {round(time.time() - start, 2)} Seconds.\")\n",
    "        \n",
    "    print(f\"Trained Params: alpha: {final_alpha}, beta: {final_beta}, W: {W.tolist()}\")\n",
    "\n",
    "    return best_nll, final_alpha, final_beta, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0001! = 6.007541656494141\n",
      "-1! = inf\n"
     ]
    }
   ],
   "source": [
    "### numerically stable factorial\n",
    "factorial = lambda x : torch.exp(torch.lgamma(x+1))\n",
    "\n",
    "assert factorial(torch.tensor(3.)) == torch.tensor(6.)\n",
    "print(f\"3.0001! = {factorial(torch.tensor(3.001)).item()}\")\n",
    "\n",
    "### notice this is infinity, so we can't call factorial on negative stuff\n",
    "print(f\"-1! = {factorial(torch.tensor(-1.)).item()}\")\n",
    "\n",
    "def compute_log_joint(u_mat, x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x_batch (size [batch_size, 3])\n",
    "        y_batch (size [batch_size])\n",
    "        u_mat   (size [batch_size, grid_size])\n",
    "        (log_alpha, log_beta, W) trainable params \n",
    "    \n",
    "    Returns:\n",
    "        torch.tensor (size [batch_size, grid_size]), where the (i,j)th element \n",
    "        is the log joint probability (log p(u, x, y; theta)). Here u is the (i,j)th\n",
    "        element of u_mat, x is the ith row of x_batch, y is the ith element of y_batch\n",
    "\n",
    "    \"\"\"\n",
    "    assert list(u_mat.size())   == [batch_size, grid_size] \n",
    "    assert list(x_batch.size()) == [batch_size, speech_len]\n",
    "    assert list(y_batch.size()) == [batch_size]\n",
    "\n",
    "    if not torch.all((u_mat >= 0).float() == y_batch.unsqueeze(1)).item():\n",
    "        raise ValueError(f\"u_mat is incompatible with y_batch.\")\n",
    "\n",
    "    ### log prior: log p(u) = log(1/4 Beta((u+1)/2; a, b) + 1/4 Beta((u+1)/2; b, a))\n",
    "    ###                     = log(1/4) + log(Beta((u+1)/2; a, b) + Beta((u+1)/2; b, a))\n",
    "    alpha = torch.exp(log_alpha)\n",
    "    beta  = torch.exp(log_beta)\n",
    "        \n",
    "    beta_dist_ab = Beta(alpha, beta)\n",
    "    beta_dist_ba = Beta(beta, alpha)\n",
    "\n",
    "    ### see 3-6 testing.ipynb test1 to see how log_prob broadcasts\n",
    "    log_beta_prob_ab = beta_dist_ab.log_prob((u_mat + 1) / 2)\n",
    "    log_beta_prob_ba = beta_dist_ba.log_prob((u_mat + 1) / 2)\n",
    "\n",
    "    prior = torch.log(torch.exp(log_beta_prob_ab) + torch.exp(log_beta_prob_ba)) + torch.log(torch.tensor(0.25))\n",
    "\n",
    "    assert list(prior.size()) == [batch_size, grid_size]\n",
    "  \n",
    "    ### log likelihood: log p(x, y | u) = dot(x, log Softmax(Wu)) + log(S!/(x1! x2! x3!)) \n",
    "\n",
    "    ### step 1: compute Wu (see 3-6 testing.ipynb test2 to see this logic)\n",
    "    W_expanded = W.unsqueeze(0).unsqueeze(0)\n",
    "    u_expanded = u_mat.unsqueeze(2)\n",
    "    Wu = torch.matmul(u_expanded, W_expanded) \n",
    "\n",
    "    assert list(W_expanded.size()) == [1,1,3 * lex_size]\n",
    "    assert list(u_expanded.size()) == [batch_size, grid_size, 1]\n",
    "    assert list(Wu.size()) == [batch_size, grid_size, 3 * lex_size]\n",
    "\n",
    "    ### step 2: dot(x, log Softmax(Wu)) (see 3-6 testing.ipynb test3 to see this logic)\n",
    "    ones = torch.ones_like(x_batch, dtype=torch.float)\n",
    "    # Assuming x_batch needs to be adjusted by -1 for 0-indexing\n",
    "    x_batch_adjusted = x_batch - 1\n",
    "    x_batch_trans = torch.zeros(batch_size, 3 * lex_size, dtype=torch.float)\n",
    "    ones = torch.ones_like(x_batch, dtype=torch.float)\n",
    "\n",
    "    x_batch_trans.scatter_add_(dim=1, index=x_batch_adjusted.long(), src=ones)\n",
    "    likelihood = (x_batch_trans.unsqueeze(1) * log_softmax(Wu, dim=2)).sum(dim=2)\n",
    "\n",
    "    ### ensure not taking negative factorials\n",
    "    assert torch.all(x_batch >= 0)\n",
    "\n",
    "    assert list(likelihood.size()) == [batch_size, grid_size]\n",
    "    return prior + likelihood\n",
    "\n",
    "\n",
    "def compute_nll(x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x_batch (size [batch_size, 3])\n",
    "        y_batch (size [batch_size])\n",
    "        log_alpha, log_beta, W (trainable params)\n",
    "        grid_size (int) number of lin spaced points to discretize integral into\n",
    "    \n",
    "    Returns:\n",
    "        quantity s.t. .backward() would be the gradient of the nll\n",
    "    \"\"\"\n",
    "    ### see 3-6 testing.ipynb test5 to see this logic\n",
    "    u_mat = torch.empty(batch_size, grid_size)\n",
    "    u_mat[y_batch == 1] = torch.linspace(1/(grid_size+1), 1-1/(grid_size+1), grid_size).repeat((y_batch == 1).sum(), 1)\n",
    "    u_mat[y_batch == 0] = torch.linspace(-1+1/(grid_size+1), -1/(grid_size+1), grid_size).repeat((y_batch == 0).sum(), 1)\n",
    "\n",
    "    assert list(u_mat.size()) == [batch_size, grid_size]\n",
    "\n",
    "    log_joint = compute_log_joint(u_mat, x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size)\n",
    "    assert list(log_joint.size()) == [batch_size, grid_size]\n",
    "\n",
    "    ### see 3-6 testing.ipynb test6 to see this logic\n",
    "    max_log_prob = torch.max(log_joint, dim=1, keepdim=True)[0]\n",
    "    joint_probs = torch.exp(log_joint - max_log_prob)\n",
    "    posterior = joint_probs / joint_probs.sum(dim=1, keepdim=True) \n",
    "    # detach posterior (see 3-6 testing.ipynb test7 to verify this works)\n",
    "    weighted_log_joint = posterior.detach() * log_joint\n",
    "    nll = -weighted_log_joint.sum()\n",
    "\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Data Generation...\n",
      "====================\n",
      "Lex Size: 5, Rho: 0.9, N: 50000\n",
      "epsilon: 0.0, pi: 0.5, S: 50\n",
      "\n",
      "True Alpha: 26.099999999999973\n",
      "True Beta: 2.8999999999999964\n",
      "\n",
      "mixture samples: [0 0 0]\n",
      "u samples: [-0.5642138  -0.92941731 -0.63742607]\n",
      "y samples: [0 0 0]\n",
      "\n",
      "P(L) = 0.15642138042073847, P(R): 0.04357861957926153, P(N): 0.0\n",
      "P(L) = 0.19294173065395445, P(R): 0.007058269346045543, P(N): 0.0\n",
      "P(L) = 0.16374260689035045, P(R): 0.03625739310964955, P(N): 0.0\n",
      "X samples (counts):\n",
      " [[ 6  8  9  6  7  4  1  3  2  4  0  0  0  0  0]\n",
      " [ 9  7 11  7 13  0  0  2  1  0  0  0  0  0  0]\n",
      " [10  8  5  8  9  3  1  3  0  3  0  0  0  0  0]]\n",
      "\n",
      "X samples (sequences):\n",
      " [[0 0 1 7 3 2 2 0 3 1 4 4 1 5 0 1 7 8 8 4 2 4 3 5 9 0 4 1 3 1 5 5 2 9 2 1\n",
      "  2 2 3 9 6 1 4 9 4 2 0 3 2 7]\n",
      " [0 2 3 3 4 1 1 4 3 3 1 7 3 2 4 4 2 1 4 0 4 2 4 2 2 2 1 0 4 8 2 0 0 4 3 0\n",
      "  2 2 4 3 1 1 2 4 0 0 0 7 4 4]\n",
      " [0 4 0 1 3 3 7 9 3 1 1 6 9 0 2 3 1 1 4 4 5 0 0 2 0 1 4 4 9 0 0 7 2 4 5 1\n",
      "  3 0 2 5 0 2 3 4 3 1 7 4 3 4]]\n",
      "\n",
      "====================\n",
      "Generation Time: 1.748 seconds for 50000 samples.\n"
     ]
    }
   ],
   "source": [
    "rho = 0.9\n",
    "N = 50000\n",
    "epsilon = 0.\n",
    "lex_size = 5\n",
    "speech_len = 50\n",
    "\n",
    "known, unknown = generate(rho=rho, N=N, verbose='high', epsilon=epsilon, lex_size=lex_size, speech_len=speech_len)\n",
    "X, y = known \n",
    "a, b, rho, epsilon, u, lex_size = unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Inference...\n",
      "====================\n",
      "Hyperparameters:\n",
      "Dataset Length: 50000\n",
      "Number Epochs: 200\n",
      "Batch Size: 100\n",
      "Grid Size: 1000\n",
      "Learning Rate: 0.1\n",
      "Improvement Threshold: 1e-05\n",
      "Patience: 100\n",
      "Speech Len: 50\n",
      "====================\n",
      "Initial Parameters:\n",
      "Alpha: 13.5\n",
      "Beta: 1.5\n",
      "W: [0.02502315863966942, -0.3245088458061218, 0.2878694534301758, 1.0578700304031372, 0.9620521664619446, 0.39347872138023376, 1.1322051286697388, -0.5403615832328796, -2.210235357284546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_nll, final_alpha, final_beta, W \u001b[39m=\u001b[39m train(X, y, patience\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, grid_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, num_epochs\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m.1\u001b[39m, speech_len\u001b[39m=\u001b[39mspeech_len,\n\u001b[1;32m      2\u001b[0m     log_alpha \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mlog(\u001b[39m13.5\u001b[39m), requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), log_beta\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mlog(\u001b[39m1.5\u001b[39m), requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "Cell \u001b[0;32mIn[5], line 77\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X, y, log_alpha, log_beta, W, num_epochs, batch_size, grid_size, lr, verbose, threshold, patience, speech_len, lex_size)\u001b[0m\n\u001b[1;32m     74\u001b[0m nll \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m---> 77\u001b[0m     nll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m compute_nll(x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size)\n\u001b[1;32m     79\u001b[0m nll \u001b[39m=\u001b[39m nll \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m     80\u001b[0m nll\u001b[39m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m, in \u001b[0;36mcompute_nll\u001b[0;34m(x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m u_mat[y_batch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(grid_size\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(grid_size\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), grid_size)\u001b[39m.\u001b[39mrepeat((y_batch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum(), \u001b[39m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlist\u001b[39m(u_mat\u001b[39m.\u001b[39msize()) \u001b[39m==\u001b[39m [batch_size, grid_size]\n\u001b[0;32m---> 89\u001b[0m log_joint \u001b[39m=\u001b[39m compute_log_joint(u_mat, x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size)\n\u001b[1;32m     90\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlist\u001b[39m(log_joint\u001b[39m.\u001b[39msize()) \u001b[39m==\u001b[39m [batch_size, grid_size]\n\u001b[1;32m     92\u001b[0m \u001b[39m### see 3-6 testing.ipynb test6 to see this logic\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 61\u001b[0m, in \u001b[0;36mcompute_log_joint\u001b[0;34m(u_mat, x_batch, y_batch, log_alpha, log_beta, W, grid_size, batch_size, speech_len, lex_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m ones \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones_like(x_batch, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     60\u001b[0m x_batch_trans \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(speech_len, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m---> 61\u001b[0m x_batch_trans\u001b[39m.\u001b[39mscatter_add_(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, index\u001b[39m=\u001b[39mx_batch\u001b[39m.\u001b[39mlong(), src\u001b[39m=\u001b[39mones)\n\u001b[1;32m     62\u001b[0m likelihood \u001b[39m=\u001b[39m (x_batch_trans\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m log_softmax(Wu, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[39m### ensure not taking negative factorials\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "best_nll, final_alpha, final_beta, W = train(X, y, patience=100, grid_size=1000, num_epochs=200, lr=.1, speech_len=speech_len,\n",
    "    log_alpha = torch.tensor(np.log(13.5), requires_grad=True), log_beta=torch.tensor(np.log(1.5), requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(a_hat, b_hat, a_true, b_true):\n",
    "    pred_dist = Beta(a_hat, b_hat)\n",
    "    true_dist = Beta(a_true, b_true)\n",
    "    \n",
    "    kl_div    = kl_divergence(pred_dist, true_dist)\n",
    "    print(f'KL Divergence: {kl_div}')\n",
    "    return kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('fictitious')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3121cab126e9bc214d9c30934815672d7d73cf142023432050561f8ae595f616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
